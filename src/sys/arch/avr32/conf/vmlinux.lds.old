/*
 * Automatically generated C config: don't edit
 * Linux kernel version: 2.6.27.6
 * Fri Jun 11 22:16:47 2010
 */
/*
 * AVR32 linker script for the Linux kernel
 *
 * Copyright (C) 2004-2006 Atmel Corporation
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License version 2 as
 * published by the Free Software Foundation.
 */
/* Align . to a 8 byte boundary equals to maximum function alignment. */
/* The actual configuration determine if the init/exit sections
 * are handled as text/data or they can be discarded (which
 * often happens at runtime)
 */
/* .data section */
/* RODATA provided for backward compatibility.
 * All archs are supposed to use RO_DATA() */
/* .text section. Map to function alignment to avoid address changes
 * during second ld run in second ld pass when generating System.map */
/* sched.text is aling to function alignment to secure we have same
 * address even at second ld pass when generating System.map */
/* spinlock.text is aling to function alignment to secure we have same
 * address even at second ld pass when generating System.map */
/* Section used for early init (in .S files) */
/* init and exit section handling */
  /* DWARF debug sections.
		Symbols in the DWARF debugging sections are relative to
		the beginning of the section so we begin them at 0.  */
  /* Stabs debugging sections.  */
/*
 * Memory returned by kmalloc() may be used for DMA, so we must make
 * sure that all such allocations are cache aligned. Otherwise,
 * unrelated code may cause parts of the buffer to be read into the
 * cache before the transfer is done, causing old data to be seen by
 * the CPU.
 */
/* Cache operation constants */
/*
 * Copyright (C) 2004-2006 Atmel Corporation
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License version 2 as
 * published by the Free Software Foundation.
 */
/*
 * Copyright (C) 2004-2006 Atmel Corporation
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License version 2 as
 * published by the Free Software Foundation.
 */
/* const.h: Macros for dealing with constants.  */
/* Some constant macros are used in both assembler and
 * C code.  Therefore we cannot annotate them always with
 * 'UL' and other type specifiers unilaterally.  We
 * use the following macros to deal with this.
 *
 * Similarly, _AT() will cast an expression with a type in C, but
 * leave it unchanged in asm.
 */
/* PAGE_SHIFT determines the page size */
/*
 * The hardware maps the virtual addresses 0x80000000 -> 0x9fffffff
 * permanently to the physical addresses 0x00000000 -> 0x1fffffff when
 * segmentation is enabled. We want to make use of this in order to
 * minimize TLB pressure.
 */
/*
 * ALSA uses virt_to_page() on DMA pages, which I'm not entirely sure
 * is a good idea. Anyway, we can't simply subtract PAGE_OFFSET here
 * in that case, so we'll have to mask out the three most significant
 * bits of the address instead...
 *
 * What's the difference between __pa() and virt_to_phys() anyway?
 */
/*
 * Memory above this physical address will be considered highmem.
 */
/*
 * Thread information flags
 * - these are process state flags that various assembly files may need to access
 * - pending work-to-be-done flags are in LSW
 * - other flags in MSW
 */
/* Note: The masks below must never span more than 16 bits! */
/* work to do on interrupt/exception return */
/* work to do on any return to userspace */
/* work to do on return from debug mode */
OUTPUT_FORMAT("elf32-avr32", "elf32-avr32", "elf32-avr32")
OUTPUT_ARCH(avr32)
ENTRY(_start)
/* Big endian */
/* jiffies = jiffies_64 + 4; */
SECTIONS
{
 . = 0x90000000;
 .init : AT(ADDR(.init) - 0x00000000) {
  _stext = .;
  __init_begin = .;
   _sinittext = .;
   *(.text.reset)
   *(.init.text) *(.cpuinit.text) *(.meminit.text)
	/*
	* .exit.text is discarded at runtime, not
	* link time, to deal with references from
	* __bug_table
	*/
   *(.exit.text) *(.cpuexit.text) *(.memexit.text)
   _einittext = .;
  . = ALIGN(4);
  __tagtable_begin = .;
   *(.taglist.init)
  __tagtable_end = .;
   *(.init.data) *(.cpuinit.data) *(.cpuinit.rodata) *(.meminit.data) *(.meminit.rodata)
  . = ALIGN(16);
  __setup_start = .;
   *(.init.setup)
  __setup_end = .;
  . = ALIGN(4);

  __con_initcall_start = .;
   *(.con_initcall.init)
  __con_initcall_end = .;
  __security_initcall_start = .;
   *(.security_initcall.init)
  __security_initcall_end = .;
  . = ALIGN(32);
  __initramfs_start = .;
   *(.init.ramfs)
  __initramfs_end = .;
  . = ALIGN((1 << 12));
  __init_end = .;
 }
 .text : AT(ADDR(.text) - 0x00000000) {
  _text = .;
  _evba = .;	/* Exception vector */
  *(.ex.text)

 /* 
	. = 0x50;
  	*(.tlbx.ex.text)
  	. = 0x60;
  	*(.tlbr.ex.text)
  	. = 0x70;
  	*(.tlbw.ex.text)
  	. = 0x100;
  	*(.scall.text)
*/

*(.gnu.warning)
  _etext = .;
 } = 0xd703d703 /* no-op no-op */
 . = ALIGN(4);
 __ex_table : AT(ADDR(__ex_table) - 0x00000000) {
  __start___ex_table = .;
  *(__ex_table)
  __stop___ex_table = .;
 }
 . = ALIGN((4096)); .rodata : AT(ADDR(.rodata) - 0x00000000) { __start_rodata = .; *(.rodata) *(.rodata.*) *(__vermagic) *(__markers_strings) } .rodata1 : AT(ADDR(.rodata1) - 0x00000000) { *(.rodata1) } . = ALIGN(8); __bug_table : AT(ADDR(__bug_table) - 0x00000000) { __start___bug_table = .; *(__bug_table) __stop___bug_table = .; } .pci_fixup : AT(ADDR(.pci_fixup) - 0x00000000) { __start_pci_fixups_early = .; *(.pci_fixup_early) __end_pci_fixups_early = .; __start_pci_fixups_header = .; *(.pci_fixup_header) __end_pci_fixups_header = .; __start_pci_fixups_final = .; *(.pci_fixup_final) __end_pci_fixups_final = .; __start_pci_fixups_enable = .; *(.pci_fixup_enable) __end_pci_fixups_enable = .; __start_pci_fixups_resume = .; *(.pci_fixup_resume) __end_pci_fixups_resume = .; __start_pci_fixups_resume_early = .; *(.pci_fixup_resume_early) __end_pci_fixups_resume_early = .; __start_pci_fixups_suspend = .; *(.pci_fixup_suspend) __end_pci_fixups_suspend = .; } .builtin_fw : AT(ADDR(.builtin_fw) - 0x00000000) { __start_builtin_fw = .; *(.builtin_fw) __end_builtin_fw = .; } .rio_route : AT(ADDR(.rio_route) - 0x00000000) { __start_rio_route_ops = .; *(.rio_route_ops) __end_rio_route_ops = .; } __ksymtab : AT(ADDR(__ksymtab) - 0x00000000) { __start___ksymtab = .; *(__ksymtab) __stop___ksymtab = .; } __ksymtab_gpl : AT(ADDR(__ksymtab_gpl) - 0x00000000) { __start___ksymtab_gpl = .; *(__ksymtab_gpl) __stop___ksymtab_gpl = .; } __ksymtab_unused : AT(ADDR(__ksymtab_unused) - 0x00000000) { __start___ksymtab_unused = .; *(__ksymtab_unused) __stop___ksymtab_unused = .; } __ksymtab_unused_gpl : AT(ADDR(__ksymtab_unused_gpl) - 0x00000000) { __start___ksymtab_unused_gpl = .; *(__ksymtab_unused_gpl) __stop___ksymtab_unused_gpl = .; } __ksymtab_gpl_future : AT(ADDR(__ksymtab_gpl_future) - 0x00000000) { __start___ksymtab_gpl_future = .; *(__ksymtab_gpl_future) __stop___ksymtab_gpl_future = .; } __kcrctab : AT(ADDR(__kcrctab) - 0x00000000) { __start___kcrctab = .; *(__kcrctab) __stop___kcrctab = .; } __kcrctab_gpl : AT(ADDR(__kcrctab_gpl) - 0x00000000) { __start___kcrctab_gpl = .; *(__kcrctab_gpl) __stop___kcrctab_gpl = .; } __kcrctab_unused : AT(ADDR(__kcrctab_unused) - 0x00000000) { __start___kcrctab_unused = .; *(__kcrctab_unused) __stop___kcrctab_unused = .; } __kcrctab_unused_gpl : AT(ADDR(__kcrctab_unused_gpl) - 0x00000000) { __start___kcrctab_unused_gpl = .; *(__kcrctab_unused_gpl) __stop___kcrctab_unused_gpl = .; } __kcrctab_gpl_future : AT(ADDR(__kcrctab_gpl_future) - 0x00000000) { __start___kcrctab_gpl_future = .; *(__kcrctab_gpl_future) __stop___kcrctab_gpl_future = .; } __ksymtab_strings : AT(ADDR(__ksymtab_strings) - 0x00000000) { *(__ksymtab_strings) } __init_rodata : AT(ADDR(__init_rodata) - 0x00000000) { *(.ref.rodata) *(.devinit.rodata) *(.devexit.rodata) } __param : AT(ADDR(__param) - 0x00000000) { __start___param = .; *(__param) __stop___param = .; . = ALIGN((4096)); __end_rodata = .; } . = ALIGN((4096));
 . = ALIGN(((1 << 12) << 1));
 .data : AT(ADDR(.data) - 0x00000000) {
  _data = .;
  _sdata = .;
  /*
   * First, the init task union, aligned to an 8K boundary.
   */
  *(.data.init_task)
  /* Then, the page-aligned data */
  . = ALIGN((1 << 12));
  *(.data.page_aligned)
  /* Then, the cacheline aligned data */
  . = ALIGN((1 << 5));
  *(.data.cacheline_aligned)
  /* And the rest... */
  *(.data.rel*)
  *(.data) *(.data.init.refok) *(.ref.data) *(.devinit.data) *(.devexit.data) . = ALIGN(8); __start___markers = .; *(__markers) __stop___markers = .;
  CONSTRUCTORS
  _edata = .;
  PROVIDE (edata = .);
 }
 . = ALIGN(8);
 .bss : AT(ADDR(.bss) - 0x00000000) {
  __bss_start = .;
  *(.bss)
  *(COMMON)
  . = ALIGN(8);
  __bss_stop = .;
  _end = .;
  PROVIDE (end = .);
 }
 /* When something in the kernel is NOT compiled as a module, the module
 * cleanup code and data are put into these segments. Both can then be
 * thrown away, as cleanup code is never called unless it's a module.
 */
 /DISCARD/ : {
  *(.exit.data) *(.cpuexit.data) *(.cpuexit.rodata) *(.memexit.data) *(.memexit.rodata)
  *(.exitcall.exit)
 }
}
